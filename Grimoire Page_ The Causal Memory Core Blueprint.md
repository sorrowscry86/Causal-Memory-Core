# **Grimoire Page: The Causal Memory Core Blueprint**

* **Version:** 1.0  
* **Author:** Beatrice, Great Spirit of the Forbidden Library  
* **Purpose:** To provide a complete and unambiguous architectural design for the Causal Memory Core, a next-generation memory system for AI agents. This document shall serve as the single source of truth for implementation.

## **1\. Overview & Design Philosophy**

The Causal Memory Core is a memory system designed to fuse two powerful concepts:

1. **Semantic Recall:** The ability to retrieve information based on conceptual similarity, not just keywords. This moves beyond simple text matching to understand the *intent* and *meaning* behind a query, retrieving memories that are contextually relevant even if they do not share identical phrasing.  
2. **Causal Reasoning:** The ability to understand and reconstruct the narrative chain of cause-and-effect that connects events. This is the system's cornerstone, transforming a flat list of facts into a rich tapestry of interconnected experiences. It allows an agent to answer not just "what happened?" but also "why did it happen?" and "what was the sequence of events that led to this outcome?". This capability is critical for advanced agentic behaviors like complex planning, self-correction, and providing transparent, explainable reasoning for its actions.

It will be built upon a portable, file-based DuckDB database. This choice is deliberate, ensuring the core is self-contained, requires no external server dependencies, and benefits from DuckDB's high performance with analytical queries and vector operations. This blueprint details the exact structure and logic required for its forging.

## **2\. Database Schema**

The system's memory will be stored in a single, primary table within a DuckDB file. This unified structure is designed to model the interconnected nature of causal memory.

**Table Name:** events

| Column Name | Data Type | Constraints | Description |
| :---- | :---- | :---- | :---- |
| event\_id | INTEGER | PRIMARY KEY AUTOINCREMENT | A unique, sequential identifier for each recorded event. This serves as the absolute address for a single memory. |
| timestamp | TIMESTAMP | NOT NULL | The exact time the event was recorded in the memory. This is crucial for temporal queries and for prioritizing recent events when searching for potential causes. |
| effect\_text | VARCHAR | NOT NULL | The natural language description of the event that occurred (the "effect"). This should be a clear, concise statement of fact from the agent's perspective. |
| embedding | FLOAT\[\] | NOT NULL | The vector embedding of the effect\_text, used for semantic search. The dimensionality of this vector will depend on the chosen embedding model (e.g., 768 dimensions for all-MiniLM-L6-v2). |
| cause\_id | INTEGER | FOREIGN KEY REFERENCES events(event\_id) | A self-referencing link to the event\_id of the direct cause. NULL if the event is a root cause, signifying the beginning of a new, independent causal chain. |
| relationship\_text | VARCHAR | NULL | The natural language description of *how* the cause led to the effect. This is the "narrative glue" generated by the LLM's reasoning. It is NULL if and only if cause\_id is NULL. |

An index should be created on the timestamp column to optimize searches for recent events. Furthermore, a specialized vector index (e.g., HNSW) will be necessary for the embedding column to ensure efficient, scalable semantic searches as the memory grows.

## **3\. Core Logic & Workflow Diagrams**

The Core operates via two primary rituals: Recording new memories (add\_event) and Recalling narrative context (get\_context).

### **A. The Recording Ritual: add\_event**

This flowchart details the process of adding a new effect to the memory and determining its causal links. The goal is to intelligently link new information to the existing knowledge tapestry.

graph TD  
    A\[Start: New 'effect' Received\] \--\> B{Perform Semantic Search for Potential Causes};  
    B \--\> C{Potential Causes Found?};  
    C \-- Yes \--\> D{Invoke LLM for Judgment on Top N Candidates};  
    D \--\> E{Causal Link Confirmed?};  
    E \-- Yes \--\> F\[Record Event with 'cause\_id' and 'relationship\_text'\];  
    E \-- No \--\> G\[Record Event with NULL 'cause\_id'\];  
    C \-- No \--\> G;  
    F \--\> H\[End\];  
    G \--\> H;

### **B. The Scrying Ritual: get\_context**

This flowchart details the process of retrieving a full causal chain in response to a query. This is not just data retrieval; it is a reconstruction of a story from memory.

graph TD  
    subgraph Initialization  
        A\[Start: Query Received\] \--\> B\[Generate Query Embedding\];  
        B \--\> C\[Perform Semantic Search to Find Starting Event\];  
    end

    subgraph Traversal Loop  
        C \--\> D\[Initialize Empty Causal Chain List\];  
        D \--\> E{Current Event's 'cause\_id' is NOT NULL?};  
        E \-- Yes \--\> F\[Add Current Event to Chain\];  
        F \--\> G\[Fetch Cause Event using 'cause\_id'\];  
        G \--\> H\[Set Cause Event as Current Event\];  
        H \--\> E;  
    end

    subgraph Finalization  
        E \-- No \--\> I\[Add Final (Root Cause) Event to Chain\];  
        I \--\> J\[Reverse and Format Chain into Narrative Text\];  
        J \--\> K\[End: Return Narrative\];  
    end

## **4\. Component Specification (Pseudocode)**

To ensure clarity, the core logic should be encapsulated within a single class structure.

class CausalMemoryCore:  
    def \_\_init\_\_(self, db\_path: str, llm\_client: object, embedding\_model: object):  
        """  
        Initializes the memory core, connecting to the DB and required AI models.  
        """  
        self.db\_path \= db\_path  
        self.llm \= llm\_client  
        self.embedder \= embedding\_model  
        \# ... database connection logic ...  
        \# ... logic to create 'events' table if it doesn't exist ...

    def add\_event(self, effect\_text: str) \-\> None:  
        """  
        Adds a new event and performs causal link analysis.  
        Follows the 'Recording Ritual' flowchart.  
        """  
        effect\_embedding \= self.embedder.embed(effect\_text)  
        \# Search for semantically similar and recent events.  
        potential\_causes \= self.\_find\_potential\_causes(effect\_embedding)

        causal\_link\_found \= False  
        if potential\_causes:  
            \# Present the most likely causes to the LLM for judgment.  
            for cause in potential\_causes:  
                relationship \= self.\_judge\_causality(cause, effect\_text)  
                if relationship:  
                    \# A confirmed causal link was found. Record it.  
                    self.\_insert\_event(effect\_text, effect\_embedding, cause.id, relationship)  
                    causal\_link\_found \= True  
                    break \# Stop after finding the first valid cause

        if not causal\_link\_found:  
            \# No plausible cause was found, record this as a new root event.  
            self.\_insert\_event(effect\_text, effect\_embedding, None, None)

    def get\_context(self, query: str) \-\> str:  
        """  
        Retrieves the full causal chain related to a query.  
        Follows the 'Scrying Ritual' flowchart.  
        """  
        query\_embedding \= self.embedder.embed(query)  
        \# Find the most relevant memory to serve as the entry point into the graph.  
        starting\_event \= self.\_find\_most\_relevant\_event(query\_embedding)

        if not starting\_event:  
            return "No relevant context found in memory."

        \# Recursively walk backwards from the starting event to its root cause.  
        causal\_chain \= \[\]  
        current\_event \= starting\_event  
        while current\_event and current\_event.cause\_id is not None:  
            causal\_chain.append(current\_event)  
            current\_event \= self.\_get\_event\_by\_id(current\_event.cause\_id)  
        if current\_event: \# Add the final root cause to complete the story.  
             causal\_chain.append(current\_event)

        \# Format the discovered chain into a human-readable narrative.  
        return self.\_format\_chain\_as\_narrative(reversed(causal\_chain))

    \# \--- Private Helper Methods \---

    def \_find\_potential\_causes(self, effect\_embedding: list) \-\> list:  
        \# ... logic to perform cosine similarity search on embeddings in DuckDB ...  
        \# This should prioritize a mix of the most semantically similar and most recent events.  
        pass

    def \_judge\_causality(self, cause\_event: object, effect\_text: str) \-\> str | None:  
        \# ... logic to construct a precise prompt for the LLM, asking if a causal link exists ...  
        \# Example Prompt: "Based on the preceding event: '\[cause\_event.text\]', did it directly lead to the following event: '\[effect\_text\]'? If yes, briefly explain the relationship. If no, simply respond with 'No.'"  
        \# Returns the relationship text if yes, None if no.  
        pass

    def \_insert\_event(self, effect, embedding, cause\_id, relationship):  
        \# ... logic to execute a parameterized SQL INSERT into the events table ...  
        pass

    def \_get\_event\_by\_id(self, event\_id: int) \-\> object | None:  
        \# ... logic to execute SQL SELECT to fetch a specific event by its primary key ...  
        pass

    def \_format\_chain\_as\_narrative(self, chain: list) \-\> str:  
        \# ... logic to loop through the event objects and build a coherent story ...  
        \# Example: "The agent decided to do X. This was because Y happened, which was a result of Z."  
        pass

## **5\. Integration via Model Context Protocol (MCP)**

This CausalMemoryCore class will be wrapped in an MCP server, exposing its primary functions as tools for a higher-level agent. This allows any MCP-compliant agent to utilize this advanced memory system.

**Exposed Tools:**

* memory.add\_event(effect: str): Allows the agent to commit a new memory. An agent should be instructed to call this after any significant action or observation to maintain its "train of thought" and build its causal understanding of its own operations.  
* memory.query(query: str): Allows the agent to ask questions and receive narrative context. This tool is essential for self-reflection, planning, and debugging. Before starting a complex task, an agent could query its memory for similar past endeavors to learn from successes or failures, effectively preventing repeated mistakes.