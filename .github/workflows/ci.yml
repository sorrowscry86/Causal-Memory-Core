name: ğŸ§  Causal Memory Core CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: "3.8"

jobs:
  test:
    name: ğŸ§ª Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11"]

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: ğŸ“¦ Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: ğŸ¯ Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics

    - name: ğŸ” Type check with mypy
      run: |
        mypy src/ --ignore-missing-imports

    - name: ğŸ§ª Run unit tests
      run: |
        python -m pytest tests/test_*.py -v --cov=src --cov-report=xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: ğŸ”— Run integration tests
      run: |
        python -m pytest tests/integration/ -v
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: ğŸ“Š Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  security:
    name: ğŸ”’ Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ›¡ï¸ Run safety check
      run: |
        pip install safety
        safety check

    - name: ğŸ” Run bandit security linter
      run: |
        pip install bandit
        bandit -r src/ -f json -o bandit-report.json

    - name: ğŸ“Š Upload security report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-report
        path: bandit-report.json

  e2e:
    name: ğŸŒ End-to-End Tests
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: ğŸš€ Run E2E tests
      run: |
        python -m pytest tests/e2e/ -v --tb=short
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: ğŸ“Š Generate test report
      if: always()
      run: |
        python -m pytest tests/e2e/ --html=e2e-report.html --self-contained-html
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: ğŸ“¤ Upload E2E report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-report
        path: e2e-report.html

  performance:
    name: âš¡ Performance Tests
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark

    - name: ğŸƒâ€â™‚ï¸ Run performance tests
      run: |
        python -m pytest tests/performance/ -v --benchmark-only --benchmark-json=benchmark.json
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    - name: ğŸ“Š Store benchmark result
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: Python Benchmark
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true

  docker:
    name: ğŸ³ Docker Build
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ”§ Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: ğŸ—ï¸ Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: causal-memory-core:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: ğŸ§ª Test Docker image
      run: |
        docker run --rm causal-memory-core:test python -c "from src.memory_core import CausalMemoryCore; print('âœ… Import successful')"

  release:
    name: ğŸš€ Release
    runs-on: ubuntu-latest
    needs: [test, security, e2e, performance, docker]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Build package
      run: |
        python -m pip install --upgrade pip build
        python -m build

    - name: ğŸ‰ Create release
      uses: semantic-release-action/semantic-release@v4
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        PYPI_TOKEN: ${{ secrets.PYPI_TOKEN }}

  notify:
    name: ğŸ“¢ Notify
    runs-on: ubuntu-latest
    needs: [test, security, e2e, performance, docker]
    if: always()

    steps:
    - name: ğŸ’¬ Notify on success
      if: needs.test.result == 'success' && needs.security.result == 'success'
      run: |
        echo "âœ… All tests passed successfully!"

    - name: ğŸš¨ Notify on failure
      if: needs.test.result == 'failure' || needs.security.result == 'failure'
      run: |
        echo "âŒ Tests failed. Please check the logs."
        exit 1